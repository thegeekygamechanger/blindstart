<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>DivyangCam</title>
    
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>

    <style>
        body {
            margin: 0;
            padding: 20px;
            background: #000;
            color: #fff;
            font-family: Arial, sans-serif;
        }
        .container {
            max-width: 800px;
            margin: 0 auto;
        }
        .video-container {
            position: relative;
            margin: 20px 0;
        }
        video {
            width: 100%;
            border-radius: 10px;
        }
        canvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
        }
        .button {
            background: #2196F3;
            color: white;
            border: none;
            padding: 12px 24px;
            border-radius: 5px;
            cursor: pointer;
            font-size: 16px;
            margin: 5px;
        }
        .button:disabled {
            background: #666;
        }
        .status {
            margin: 10px 0;
            padding: 10px;
            background: #333;
            border-radius: 5px;
        }
        .audio-controls {
            margin: 10px 0;
        }
        #volumeControl {
            width: 200px;
            margin: 0 10px;
        }
    </style>
</head>
<body>
<h1><center>Simulation helper for Divyang People</center></h1>
    <div class="container">
        <div class="video-container">
            <video id="video" autoplay playsinline muted></video>
            <canvas id="canvas"></canvas>
        </div>

        <div>
            <button id="startBtn" class="button">Start Camera</button>
            <button id="stopBtn" class="button" disabled>Stop</button>
        </div>

        <div class="audio-controls">
            Volume: <input type="range" id="volumeControl" min="0" max="1" step="0.1" value="1">
            <button id="muteBtn" class="button">Mute Audio</button>
        </div>

        <div id="status" class="status">Loading model...</div>
    </div>

    <script>
        let model;
        let isRunning = false;
        let isMuted = false;
        let lastSpokenTime = 0;
        let lastSpokenObjects = new Map();

        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');
        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const status = document.getElementById('status');
        const volumeControl = document.getElementById('volumeControl');
        const muteBtn = document.getElementById('muteBtn');

        // Initialize speech synthesis
        const synth = window.speechSynthesis;
        let voice = null;

        // Set up voice
        function setupVoice() {
            const voices = synth.getVoices();
            voice = voices.find(v => 
                v.lang === 'en-US' && 
                (v.name.includes('Google') || v.name.includes('Natural'))
            ) || voices.find(v => v.lang === 'en-US') || voices[0];
        }

        if (synth.onvoiceschanged !== undefined) {
            synth.onvoiceschanged = setupVoice;
        }

        // Enhanced speak function
        function speak(text, priority = false) {
            if (isMuted) return;
            
            const now = Date.now();
            if (!priority && now - lastSpokenTime < 1000) return;

            if (synth.speaking && !priority) return;

            const utterance = new SpeechSynthesisUtterance(text);
            utterance.voice = voice;
            utterance.rate = 1.2;
            utterance.pitch = 1.0;
            utterance.volume = parseFloat(volumeControl.value);
            synth.speak(utterance);
            lastSpokenTime = now;
        }

        // Get direction of object
        function getDirection(x, width, canvasWidth) {
            const center = x + (width / 2);
            const third = canvasWidth / 3;
            
            if (center < third) return "on the left";
            if (center > third * 2) return "on the right";
            return "in front";
        }

        // Estimate distance
        function estimateDistance(bbox) {
            const [,, width, height] = bbox;
            const size = Math.max(width, height);
            return (500 / size).toFixed(1);
        }

        // Load model
        async function loadModel() {
            try {
                model = await cocoSsd.load();
                startBtn.disabled = false;
                status.textContent = 'Model loaded - ready to start';
                speak('System ready');
            } catch (error) {
                status.textContent = 'Error loading model: ' + error;
                console.error('Model loading error:', error);
            }
        }

        // Detect objects and provide audio feedback
        async function detectFrame() {
            if (!isRunning) return;

            try {
                const predictions = await model.detect(video);
                ctx.clearRect(0, 0, canvas.width, canvas.height);

                const currentDetections = new Map();

                predictions.forEach(prediction => {
                    if (prediction.score > 0.6) { // Higher confidence threshold
                        const [x, y, width, height] = prediction.bbox;
                        const distance = estimateDistance(prediction.bbox);
                        const direction = getDirection(x, width, canvas.width);
                        
                        // Draw detection box
                        ctx.strokeStyle = distance < 2 ? '#ff0000' : '#00ff00';
                        ctx.lineWidth = 2;
                        ctx.strokeRect(x, y, width, height);

                        // Draw label
                        ctx.fillStyle = distance < 2 ? 'rgba(255,0,0,0.8)' : 'rgba(0,255,0,0.8)';
                        ctx.fillRect(x, y - 30, width, 30);
                        ctx.fillStyle = '#ffffff';
                        ctx.font = 'bold 16px Arial';
                        ctx.fillText(
                            `${prediction.class} ${distance}m`,
                            x + 5,
                            y - 8
                        );

                        // Prepare audio announcement
                        const key = `${prediction.class}-${direction}-${Math.round(distance)}`;
                        const now = Date.now();
                        currentDetections.set(key, now);

                        // Announce new detections or significant changes
                        if (!lastSpokenObjects.has(key) || 
                            (now - lastSpokenObjects.get(key)) > 3000) {
                            
                            // Prioritize close objects
                            const priority = distance < 2;
                            const announcement = 
                                `${prediction.class} ${direction} at ${distance} meters`;
                            
                            speak(announcement, priority);
                            lastSpokenObjects.set(key, now);
                        }
                    }
                });
detectionText += `${prediction.class} ${direction} at ${distance}m (${confidence}%)\n`;

                // Clean up old detections
                for (const [key, time] of lastSpokenObjects.entries()) {
                    if (!currentDetections.has(key) || 
                        (Date.now() - time > 3000)) {
                        lastSpokenObjects.delete(key);
                    }
                }

                requestAnimationFrame(detectFrame);
            } catch (error) {
                console.error('Detection error:', error);
                if (isRunning) {
                    requestAnimationFrame(detectFrame);
                }
            }
        }

        // Start camera
        async function startCamera() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({
                    video: { 
                        facingMode: 'environment',
                        width: { ideal: 640 },
                        height: { ideal: 480 }
                    }
                });

                video.srcObject = stream;
                await video.play();

                canvas.width = video.videoWidth;
                canvas.height = video.videoHeight;

                isRunning = true;
                startBtn.disabled = true;
                stopBtn.disabled = false;
                status.textContent = 'Detection running';
                speak('Starting detection');

                detectFrame();
            } catch (error) {
                status.textContent = 'Error accessing camera: ' + error;
                console.error('Camera error:', error);
            }
        }

        // Stop camera
        function stopCamera() {
            isRunning = false;
            const stream = video.srcObject;
            if (stream) {
                stream.getTracks().forEach(track => track.stop());
                video.srcObject = null;
            }
            startBtn.disabled = false;
            stopBtn.disabled = true;
            status.textContent = 'Detection stopped';
            speak('Detection stopped');
            lastSpokenObjects.clear();
        }

        // Toggle mute
        muteBtn.addEventListener('click', () => {
            isMuted = !isMuted;
            muteBtn.textContent = isMuted ? 'Unmute Audio' : 'Mute Audio';
            if (isMuted) {
                synth.cancel(); // Stop any ongoing speech
            }
        });

        // Event listeners
        startBtn.addEventListener('click', startCamera);
        stopBtn.addEventListener('click', stopCamera);
        volumeControl.addEventListener('input', () => {
            if (isMuted) {
                isMuted = false;
                muteBtn.textContent = 'Mute Audio';
            }
        });

        // Initialize
        loadModel();
    </script>
</body>
</html><!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Audio Object Detector</title>
    
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>

    <style>
        body {
            margin: 0;
            padding: 20px;
            background: #000;
            color: #fff;
            font-family: Arial, sans-serif;
        }
        .container {
            max-width: 800px;
            margin: 0 auto;
        }
        .video-container {
            position: relative;
            margin: 20px 0;
        }
        video {
            width: 100%;
            border-radius: 10px;
        }
        canvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
        }
        .button {
            background: #2196F3;
            color: white;
            border: none;
            padding: 12px 24px;
            border-radius: 5px;
            cursor: pointer;
            font-size: 16px;
            margin: 5px;
        }
        .button:disabled {
            background: #666;
        }
        .status {
            margin: 10px 0;
            padding: 10px;
            background: #333;
            border-radius: 5px;
        }
        .audio-controls {
            margin: 10px 0;
        }
        #volumeControl {
            width: 200px;
            margin: 0 10px;
        }
    </style>
</head>
<body>


    <script>
        let model;
        let isRunning = false;
        let isMuted = false;
        let lastSpokenTime = 0;
        let lastSpokenObjects = new Map();

        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');
        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const status = document.getElementById('status');
        const volumeControl = document.getElementById('volumeControl');
        const muteBtn = document.getElementById('muteBtn');

        // Initialize speech synthesis
        const synth = window.speechSynthesis;
        let voice = null;

        // Set up voice
        function setupVoice() {
            const voices = synth.getVoices();
            voice = voices.find(v => 
                v.lang === 'en-US' && 
                (v.name.includes('Google') || v.name.includes('Natural'))
            ) || voices.find(v => v.lang === 'en-US') || voices[0];
        }

        if (synth.onvoiceschanged !== undefined) {
            synth.onvoiceschanged = setupVoice;
        }

        // Enhanced speak function
        function speak(text, priority = false) {
            if (isMuted) return;
            
            const now = Date.now();
            if (!priority && now - lastSpokenTime < 1000) return;

            if (synth.speaking && !priority) return;

            const utterance = new SpeechSynthesisUtterance(text);
            utterance.voice = voice;
            utterance.rate = 1.2;
            utterance.pitch = 1.0;
            utterance.volume = parseFloat(volumeControl.value);
            synth.speak(utterance);
            lastSpokenTime = now;
        }

        // Get direction of object
        function getDirection(x, width, canvasWidth) {
            const center = x + (width / 2);
            const third = canvasWidth / 3;
            
            if (center < third) return "on the left";
            if (center > third * 2) return "on the right";
            return "in front";
        }

        // Estimate distance
        function estimateDistance(bbox) {
            const [,, width, height] = bbox;
            const size = Math.max(width, height);
            return (500 / size).toFixed(1);
        }

        // Load model
        async function loadModel() {
            try {
                model = await cocoSsd.load();
                startBtn.disabled = false;
                status.textContent = 'Model loaded - ready to start';
                speak('System ready');
            } catch (error) {
                status.textContent = 'Error loading model: ' + error;
                console.error('Model loading error:', error);
            }
        }

        // Detect objects and provide audio feedback
        async function detectFrame() {
            if (!isRunning) return;

            try {
                const predictions = await model.detect(video);
                ctx.clearRect(0, 0, canvas.width, canvas.height);

                const currentDetections = new Map();

                predictions.forEach(prediction => {
                    if (prediction.score > 0.6) { // Higher confidence threshold
                        const [x, y, width, height] = prediction.bbox;
                        const distance = estimateDistance(prediction.bbox);
                        const direction = getDirection(x, width, canvas.width);
                        
                        // Draw detection box
                        ctx.strokeStyle = distance < 2 ? '#ff0000' : '#00ff00';
                        ctx.lineWidth = 2;
                        ctx.strokeRect(x, y, width, height);

                        // Draw label
                        ctx.fillStyle = distance < 2 ? 'rgba(255,0,0,0.8)' : 'rgba(0,255,0,0.8)';
                        ctx.fillRect(x, y - 30, width, 30);
                        ctx.fillStyle = '#ffffff';
                        ctx.font = 'bold 16px Arial';
                        ctx.fillText(
                            `${prediction.class} ${distance}m`,
                            x + 5,
                            y - 8
                        );

                        // Prepare audio announcement
                        const key = `${prediction.class}-${direction}-${Math.round(distance)}`;
                        const now = Date.now();
                        currentDetections.set(key, now);

                        // Announce new detections or significant changes
                        if (!lastSpokenObjects.has(key) || 
                            (now - lastSpokenObjects.get(key)) > 3000) {
                            
                            // Prioritize close objects
                            const priority = distance < 2;
                            const announcement = 
                                `${prediction.class} ${direction} at ${distance} meters`;
                            
                            speak(announcement, priority);
                            lastSpokenObjects.set(key, now);
                        }
                    }
                });

                // Clean up old detections
                for (const [key, time] of lastSpokenObjects.entries()) {
                    if (!currentDetections.has(key) || 
                        (Date.now() - time > 3000)) {
                        lastSpokenObjects.delete(key);
                    }
                }

                requestAnimationFrame(detectFrame);
            } catch (error) {
                console.error('Detection error:', error);
                if (isRunning) {
                    requestAnimationFrame(detectFrame);
                }
            }
        }

        // Start camera
        async function startCamera() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({
                    video: { 
                        facingMode: 'environment',
                        width: { ideal: 640 },
                        height: { ideal: 480 }
                    }
                });

                video.srcObject = stream;
                await video.play();

                canvas.width = video.videoWidth;
                canvas.height = video.videoHeight;

                isRunning = true;
                startBtn.disabled = true;
                stopBtn.disabled = false;
                status.textContent = 'Detection running';
                speak('Starting detection');

                detectFrame();
            } catch (error) {
                status.textContent = 'Error accessing camera: ' + error;
                console.error('Camera error:', error);
            }
        }

        // Stop camera
        function stopCamera() {
            isRunning = false;
            const stream = video.srcObject;
            if (stream) {
                stream.getTracks().forEach(track => track.stop());
                video.srcObject = null;
            }
            startBtn.disabled = false;
            stopBtn.disabled = true;
            status.textContent = 'Detection stopped';
            speak('Detection stopped');
            lastSpokenObjects.clear();
        }

        // Toggle mute
        muteBtn.addEventListener('click', () => {
            isMuted = !isMuted;
            muteBtn.textContent = isMuted ? 'Unmute Audio' : 'Mute Audio';
            if (isMuted) {
                synth.cancel(); // Stop any ongoing speech
            }
        });

        // Event listeners
        startBtn.addEventListener('click', startCamera);
        stopBtn.addEventListener('click', stopCamera);
        volumeControl.addEventListener('input', () => {
            if (isMuted) {
                isMuted = false;
                muteBtn.textContent = 'Mute Audio';
            }
        });

        // Initialize
        loadModel();
    </script>
    
</body>
</html>
